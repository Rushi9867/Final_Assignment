{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a program that takes a string as input, and counts the frequency of each word in the string, there might be repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the highest-frequency word: 5\n"
     ]
    }
   ],
   "source": [
    "def find_highest_frequency_word_length(string):\n",
    "    words = string.split()\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "    # Find the word with the highest frequency\n",
    "    highest_freq = 0\n",
    "    highest_freq_word = \"\"\n",
    "    for word, freq in word_freq.items():\n",
    "        if freq > highest_freq:\n",
    "            highest_freq = freq\n",
    "            highest_freq_word = word\n",
    "\n",
    "    # Return the length of the highest-frequency word\n",
    "    return len(highest_freq_word)\n",
    "\n",
    "# Example usage\n",
    "input_string = \"write write write all the number from from from 1 to 100\"\n",
    "result = find_highest_frequency_word_length(input_string)\n",
    "print(\"Length of the highest-frequency word:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the highest-frequency word: 5\n"
     ]
    }
   ],
   "source": [
    "input_string = \"apple banana apple orange orange apple\"\n",
    "result = find_highest_frequency_word_length(input_string)\n",
    "print(\"Length of the highest-frequency word:\", result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if he can remove just one character at the index in the string, and the remaining characters will occur the same number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "def string_valid(string):\n",
    "    word_freq = {}\n",
    "    for word in string:\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "    freq_count = {}\n",
    "    for freq in word_freq.values():\n",
    "        if freq in freq_count:\n",
    "            freq_count[freq] += 1\n",
    "        else:\n",
    "            freq_count[freq] = 1\n",
    "            \n",
    "        # Check the validity conditions\n",
    "    if len(freq_count) == 1:\n",
    "        # All characters appear the same number of times\n",
    "        return \"YES\"\n",
    "    elif len(freq_count) == 2:\n",
    "        # Check if removing one character can make all frequencies the same\n",
    "        freq1, count1 = freq_count.popitem()\n",
    "        freq2, count2 = freq_count.popitem()\n",
    "        if (count1 == 1 and freq1 == 1) or (count2 == 1 and freq2 == 1):\n",
    "            # Removing one character makes all frequencies the same\n",
    "            return \"YES\"\n",
    "\n",
    "    # String is not valid according to the conditions\n",
    "    return \"NO\"\n",
    "\n",
    "# Example usage\n",
    "input_string = \"abc\"\n",
    "result = string_valid(input_string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    }
   ],
   "source": [
    "input_string = \"abcc\"\n",
    "result = string_valid(input_string)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a program, which would download the data from the provided link, and then read the data and convert that into properly structured data and return it in Excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been converted and saved to PokemonGo.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def json_convert_to_excel(json_url, excel_filename):\n",
    "    # Download the JSON data\n",
    "    response = requests.get(json_url)\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Convert the JSON data into a pandas DataFrame\n",
    "    df = pd.DataFrame(json_data['pokemon'])\n",
    "\n",
    "    # Save the DataFrame as an Excel file\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    print(\"Data has been converted and saved to\", excel_filename)\n",
    "\n",
    "# Example usage\n",
    "json_url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
    "excel_filename = \"PokemonGo.xlsx\"\n",
    "\n",
    "json_convert_to_excel(json_url, excel_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a program to download the data from the link given below and then read the data and convert the into the proper structure and return it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: ':@computed_region_nnqa_25f4', ':@computed_region_cbhk_fwbd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m json_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://data.nasa.gov/resource/y77d-th95.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m csv_filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNasa_data.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 28\u001b[0m download_and_convert_to_csv(json_url, csv_filename)\n",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m, in \u001b[0;36mdownload_and_convert_to_csv\u001b[1;34m(json_url, csv_filename)\u001b[0m\n\u001b[0;32m     17\u001b[0m     writer\u001b[39m.\u001b[39mwriteheader()\n\u001b[0;32m     19\u001b[0m     \u001b[39m# Write the data rows\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     writer\u001b[39m.\u001b[39;49mwriterows(json_data)\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mData has been converted and saved to\u001b[39m\u001b[39m\"\u001b[39m, csv_filename)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\csv.py:157\u001b[0m, in \u001b[0;36mDictWriter.writerows\u001b[1;34m(self, rowdicts)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwriterows\u001b[39m(\u001b[39mself\u001b[39m, rowdicts):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter\u001b[39m.\u001b[39;49mwriterows(\u001b[39mmap\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_to_list, rowdicts))\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\csv.py:149\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    147\u001b[0m     wrong_fields \u001b[39m=\u001b[39m rowdict\u001b[39m.\u001b[39mkeys() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfieldnames\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m wrong_fields:\n\u001b[1;32m--> 149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdict contains fields not in fieldnames: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m                          \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mrepr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m wrong_fields]))\n\u001b[0;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m (rowdict\u001b[39m.\u001b[39mget(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestval) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfieldnames)\n",
      "\u001b[1;31mValueError\u001b[0m: dict contains fields not in fieldnames: ':@computed_region_nnqa_25f4', ':@computed_region_cbhk_fwbd'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "def download_and_convert_to_csv(json_url, csv_filename):\n",
    "    # Download the JSON data\n",
    "    response = requests.get(json_url)\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the headers from the JSON data\n",
    "    headers = list(json_data[0].keys())\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "\n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write the data rows\n",
    "        writer.writerows(json_data)\n",
    "\n",
    "    print(\"Data has been converted and saved to\", csv_filename)\n",
    "\n",
    "# Example usage\n",
    "json_url = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
    "csv_filename = \"Nasa_data.csv\"\n",
    "\n",
    "download_and_convert_to_csv(json_url, csv_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to download the data from the given API link and then extract the following data with proper formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 869671\n",
      "url: https://www.tvmaze.com/episodes/869671/westworld-1x01-the-original\n",
      "name: The Original\n",
      "season: 1\n",
      "number: 1\n",
      "type: regular\n",
      "airdate: 2016-10-02\n",
      "airtime: 21:00\n",
      "airstamp: 2016-10-03T01:00:00+00:00\n",
      "average_rating: 8\n",
      "medium_image: https://static.tvmaze.com/uploads/images/medium_landscape/78/195475.jpg\n",
      "original_image: https://static.tvmaze.com/uploads/images/original_untouched/78/195475.jpg\n",
      "summary: <p>A woman named Dolores is a free spirit in the Old West... and unaware that she's actually an android, programmed to entertain rich guests seeking to act out their fantasies in an idealized vision of the 1880s. However, the people in charge soon realize that their androids are acting in ways that they didn't anticipate.</p>\n",
      "self_links: {'href': 'https://api.tvmaze.com/episodes/869671'}\n",
      "show_links: {'href': 'https://api.tvmaze.com/shows/1371'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_and_extract_data(api_url):\n",
    "    # Download the JSON data from the API\n",
    "    response = requests.get(api_url)\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the desired data from the JSON response\n",
    "    extracted_data = {\n",
    "        'id' : json_data['_embedded']['episodes'][0]['id'],\n",
    "        'url' : json_data['_embedded']['episodes'][0]['url'],\n",
    "        'name': json_data['_embedded']['episodes'][0]['name'],\n",
    "        'season' : json_data['_embedded']['episodes'][0]['season'],\n",
    "        'number' : json_data['_embedded']['episodes'][0]['number'],\n",
    "        'type' : json_data['_embedded']['episodes'][0]['type'],\n",
    "        'airdate' : json_data['_embedded']['episodes'][0]['airdate'],\n",
    "        'airtime' : json_data['_embedded']['episodes'][0]['airtime'],\n",
    "        'airstamp' : json_data['_embedded']['episodes'][0]['airstamp'],\n",
    "        'average_rating' : json_data['_embedded']['episodes'][0]['rating']['average'],\n",
    "        'medium_image' : json_data['_embedded']['episodes'][0]['image']['medium'],\n",
    "        'original_image' : json_data['_embedded']['episodes'][0]['image']['original'],\n",
    "        'summary' : json_data['_embedded']['episodes'][0]['summary'],\n",
    "        'self_links': json_data['_embedded']['episodes'][0]['_links']['self'],\n",
    "        'show_links' : json_data['_embedded']['episodes'][0]['_links']['show']\n",
    "    }\n",
    "\n",
    "    # Format and print the extracted data\n",
    "    print(\"id:\", extracted_data['id'])\n",
    "    print(\"url:\", extracted_data['url'])\n",
    "    print(\"name:\", extracted_data['name'])\n",
    "    print(\"season:\", extracted_data['season'])\n",
    "    print(\"number:\", extracted_data['number'])\n",
    "    print(\"type:\", extracted_data['type'])\n",
    "    print(\"airdate:\", extracted_data['airdate'])\n",
    "    print(\"airtime:\", extracted_data['airtime'])\n",
    "    print(\"airstamp:\", extracted_data['airstamp'])\n",
    "    print(\"average_rating:\", extracted_data['average_rating'])\n",
    "    print(\"medium_image:\", extracted_data['medium_image'])\n",
    "    print(\"original_image:\", extracted_data['original_image'])\n",
    "    print(\"summary:\", extracted_data['summary'])\n",
    "    print(\"self_links:\", extracted_data['self_links'])\n",
    "    print(\"show_links:\", extracted_data['show_links'])\n",
    "\n",
    "\n",
    "# Example usage\n",
    "api_url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
    "download_and_extract_data(api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been extracted and saved to westworld.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_and_convert_to_csv(api_url, csv_filename):\n",
    "    # Download the JSON data from the API\n",
    "    response = requests.get(api_url)\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the required data from the JSON\n",
    "    extracted_data = []\n",
    "    for item in json_data['_embedded']['episodes']:\n",
    "        # Extract the desired fields from the JSON item\n",
    "        id = item['id']\n",
    "        url = item['url']\n",
    "        name = item['name']\n",
    "        season = item['season']\n",
    "        number = item['number']\n",
    "        type = item['type']\n",
    "        airdate = item['airdate']\n",
    "        airtime = item['airtime']\n",
    "        airstamp = item['airstamp']\n",
    "        average_rating = item['rating']['average']\n",
    "        medium_image = item['image']['medium']\n",
    "        original_image = item['image']['original']\n",
    "        summary  = item['summary']\n",
    "        self_links = item['_links']['self']['href']\n",
    "        show_links = item['_links']['show']['href']\n",
    "\n",
    "        # Perform necessary formatting or manipulation based on data types\n",
    "\n",
    "        if isinstance(airdate, str):\n",
    "            airdate = datetime.strptime(airdate, '%Y-%m-%d').strftime('%d-%m-%Y')  # Convert date format\n",
    "\n",
    "        if isinstance(airtime, str):\n",
    "            airtime = datetime.strptime(airtime, '%H:%M').strftime('%I:%M %p')  # Convert time format\n",
    "\n",
    "        if isinstance(airstamp, str):\n",
    "            parsed_datetime = datetime.fromisoformat(airstamp)\n",
    "            airstamp = parsed_datetime.strftime('%d-%m-%Y %I:%M %p')# Convert timestamp format\n",
    "\n",
    "        if isinstance(summary, str):\n",
    "            soup = BeautifulSoup(summary, 'html.parser')\n",
    "            summary = soup.get_text()  # Extract text from HTML\n",
    "\n",
    "        # Add the formatted data to the extracted_data list\n",
    "        extracted_data.append([id,url,name,season,number,type,airdate,airtime,airstamp,average_rating,medium_image,original_image,summary,self_links,show_links])\n",
    "\n",
    "    # Write the extracted data to a CSV file\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row\n",
    "        writer.writerow(['id', 'url', 'name', 'season', 'number', 'type','airdate','airtime','airstamp','average_rating','medium_image','original_image','summary','self_links','show_links'])\n",
    "\n",
    "        # Write the data rows\n",
    "        writer.writerows(extracted_data)\n",
    "\n",
    "    print(\"Data has been extracted and saved to\", csv_filename)\n",
    "\n",
    "# Example usage\n",
    "api_url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
    "csv_filename = \"westworld.csv\"\n",
    "\n",
    "download_and_convert_to_csv(api_url, csv_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or paragraph, and return their respective count as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'Adjectives': 2, 'Nouns': 3, 'Verbs': 1})\n"
     ]
    }
   ],
   "source": [
    "def count_pos_tags(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Perform part-of-speech tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    # Initialize a defaultdict to store the counts of each part of speech\n",
    "    pos_counts = defaultdict(int)\n",
    "\n",
    "    # Iterate over the tagged words and count the occurrences of each part of speech\n",
    "    for word, tag in tagged_words:\n",
    "        if tag.startswith('V'):  # Verbs\n",
    "            pos_counts['Verbs'] += 1\n",
    "        elif tag.startswith('N'):  # Nouns\n",
    "            pos_counts['Nouns'] += 1\n",
    "        elif tag.startswith('PRP'):  # Pronouns\n",
    "            pos_counts['Pronouns'] += 1\n",
    "        elif tag.startswith('JJ'):  # Adjectives\n",
    "            pos_counts['Adjectives'] += 1\n",
    "\n",
    "    return pos_counts\n",
    "\n",
    "# Example usage\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "counts = count_pos_tags(text)\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'Nouns': 4, 'Adjectives': 2, 'Verbs': 2})\n"
     ]
    }
   ],
   "source": [
    "text = \"Cozy lummox gives smart squid who asks for job pen\"\n",
    "counts = count_pos_tags(text)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
